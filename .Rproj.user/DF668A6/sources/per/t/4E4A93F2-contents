---
title: "Intro to exploratory analyses and univariate stats"
author: "Tracy Bowerman"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  bookdown::html_document2:
    code_folding: hide
    df_print: paged
    fig_caption: yes
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

Disclaimer: this tutorial is provided to you free of charge in the hopes that it will help you learn R and that stats and data analysis will be more accessible.  However, no decisions regarding which statistics to use when should be based on this document!  Please consult a statistician or make sure to do your own research to evaluate which statistical test is valid for your data and how to interpret your results.

In this tutorial we will explore data to look for outliers, evaluate normality and skewness, and test for equal variances.  We will conduct some basic statistics to compare sample populations.

# Learning goals
In this tutorial, you will learn how conduct some preliminary exploratory analyses and perform these tasks:
  
  -  look for outliers
  -  histograms and QQnorm plots to look for outliers and normality
  -  boxplots and various tests to evaluate variance
  -  compare the distribution of 2 populations with density plots and qqplots
  -  statistically test the difference between 2 populations using a t-test or non-parametric Mann-Whitney U test (or other similar)
  -  there is also a Chi-squared example at the end


load packages and set your working directory, just like before:
```{r setup, include=FALSE}
library(tidyverse)
dir <- getwd()
#dir <- setwd("C:/Users/Tracy/Desktop/skcr_day_2")  # if you want to change working directory
```
# Exploratory analysis 
For this and other analyses, I recommend conducting thorough exploration of data before running statistical tests.  This goes way beyond looking for mistakes and outliers, and includes evaluating the structure of your data, distributions, the potential for interactions and collinearity, and autocorrelation.  Here's a useful protocol for conducting exploratory analyses desribed by Zuur, Ieno, and Elphic in a 2010 article titled, "A protocol for data exploration to avoid common statistical problems" published in Methods in Ecology and Evolution. 

## Here's the protocol for data exploration:

1.  Check for outliers Y & X
2.  Homogeneity of variance in Y
3.  Normality in Y
4.  Too many zeros Y
5.  Collinearity X
6.  Relationships between Y & X
7.  Interactions among X
8.  Independence Y

Not all of these are applicable for every data exploration, but they are all worth considering.

# Iris data: compare 2 populations
We will use the iris data to test whether Petal.Length is significantly different between 2 populations (in this case species).  Let's remind ourselves about the structure of those data and then begin data exploration to help us understand which statistical test(s) we should use

```{r Explore iris data}

# check data structure
str(iris)
# remember, 4 different measurements taken on 3 species, 50 obs of each
par()  # view current graphical parameters
opar <- par() ## make a copy of current settings so you can reset your graphing parameters when you are done messing around below (this says: save the current parameters as something called 'opar')

par(mfrow = c(1, 2)) # layout plot area with 1 row, 2 columns

# we'll just combine two plots we have made before
plot(Petal.Length ~ Petal.Width,
     data=iris,
     xlab = "Iris Petal Width (cm)", 
     ylab = "Petal Length (cm)",
     main = "Scatterplot", 
     pch = 21,
     bg = c("magenta", "dark green", "blue")[Species]
)
# For symbols 21 through 25, specify border color (col=) and fill color (bg=)

boxplot(Petal.Length ~ Species,
        data=iris,
        col = c("magenta", "dark green", "blue"),
        main = "Boxplot", xlab = "Species", ylab = "Petal Length (cm)"
)
par(opar)
## Oh right, that setosa species was doing its own thing.  For now, we will only concern ourselves with two of the species:  virginica and versicolor
# subset the data and keep data that are not equal to the 'setosa' species
iris.sub <- iris[which(iris$Species != "setosa"), ]
iris.sub <- droplevels(iris.sub) # this gets rid of blank lines in the subset data

# or you can use piping like we did yesterday
iris.sub <- iris %>% 
  filter(Species!="setosa")
iris.sub <- droplevels(iris.sub) # this gets rid of blank lines in the subset data
```

# Working through the protocol
Now that we have the data we want to work with, let's work through the protocol.  In this case, we need steps 1-3.

```{r step 1 of the data exploration protocol: check for outliers}
# 1) check for outliers--a quick way to do this is with a dotchart
dotchart(iris.sub$Petal.Length, ylab = "Order of the data") 
# for some plots you must call the dataset and column name together

# Sometimes a histogram can also be helpful for spotting outliers
hist(iris.sub$Petal.Length, breaks = 20)
```
# no clear outliers, so we can move on to step 2

```{r step 2 of the protocol: check for homogeneity of variance}
# 2) homogeneity of variance--using boxplots and some tests
boxplot(Petal.Length ~ Species,
  data=iris.sub,
  col = c("dark green", "blue"),
  main = "Boxplot", xlab = "Species", ylab = "Petal Width (mm)"
)

# Do the lengths of the whiskers look similar betwee the two species?
# For comparison, remember what the whiskers looked like on the 'setosa' species when we included it in the boxplot

## Some of the plots in step 3 will also help us evaluate homogeneity of variance
```

## Tests for homogeneity of variance 
Numerous statistical tests such as t.tests and anova assume homogeneity of variance.  There are several different tests you can use to test this assumption.  A Bartlett test is commonly used when to check the assumption of equal variances when you have normally distributed data.  Levene's test is an alternative to Bartlett's test when the data are not normally distributed.  It is available in the 'car' package. The Fligner-Killeen test is most robust against departures from normality.  For all of these tests, non-significant result = lack of evidence of differing variances.  

```{r testing homogeneity of variance}

# bartlett test for normally distributed data
bartlett.test(Petal.Length ~ Species, data = iris.sub)

## if comparing multiple levels of a factor, this test won't tell you which one(s) have unequal variance.  For example if we use the data with all 3 spp (we know the setosa species has much smaller variance):
bartlett.test(Petal.Length ~ Species, data = iris)

# Levene's test for data that are not normally distributed. Available in the 'car' package
# library(car)
# leveneTest(Petal.Length ~ Species, data = iris.sub)

# Fligner-Killeen test for data that are not normally distributed
fligner.test(Petal.Length ~ Species, data = iris.sub)

# None of our tests suggest unequal variances so we proceed with a t-test in mind.  What are some other assumptions of a t-test?
```

## Evaluate the assumption of normality
Are our data normally distributed?
Do the two populations we are comparing have similar distributions?

```{r part 3 of protocol: check for normality}

# 3) check for normality Y with histogram
# You could plot these above one another
hist(iris.sub$Petal.Length[iris.sub$Species == "versicolor"], breaks = 10, main = "histogram of versicolor")
# a slightly different way to plot a histogram of the other species:
with(iris.sub, hist(Petal.Length[Species == "virginica"], breaks = 10, main = "histogram of virginica"))

# you can or put them on the same plot with transparent colors
par(opar)
with(iris.sub,hist(Petal.Length[Species=="versicolor"], breaks=10, xlim=c(3, 7.5), col=rgb(0,1,0,0.5), main=""))
with(iris.sub,hist(Petal.Length[Species=="virginica"], breaks=10, add=T, col=rgb(0,0,1,0.25)))
# rgb specifies the red, green, blue values plus opacity

# both populations are slightly skewed but not terrible; examine with QQ plots
qqnorm(iris.sub$Petal.Length)
qqline(iris.sub$Petal.Length)

## because we want to compare 2 pops, look at each separately:
qqnorm(iris.sub$Petal.Length[iris.sub$Species == "versicolor"])
qqline(iris.sub$Petal.Length[iris.sub$Species == "versicolor"])
qqnorm(iris.sub$Petal.Length[iris.sub$Species == "virginica"])
qqline(iris.sub$Petal.Length[iris.sub$Species == "virginica"])
# neither is perfectly normal but neither is terrible

# use qqplot to compare the quantiles of the two populations (in other words, plot the quantiles of one species against the quantiles of the other):
qqplot(iris.sub$Petal.Length[iris.sub$Species == "virginica"], iris.sub$Petal.Length[iris.sub$Species == "versicolor"])
abline(-1.4, 1)
# confirms-not exactly equal distributions, but not terrible

# a density plot is another way to view distributions
with(iris, plot(density(Petal.Length[Species == "versicolor"]),
  xlim = c(2.5, 7.3), ylim = c(0, 0.85), main = "density plot",
  xlab = "Petal length"
))
# add a line for the other species on top of plot of previous species
with(iris, lines(density(Petal.Length[Species == "virginica"]), col = "red"))
```

## Tests of normality
Many statistical tests also assume that data come from a normal distribution.  The t-test is fairly robust to this assumption, but it is still a good idea to check.  There are several different tests for normality, so you can choose your favorite or do more background research into which best fits your needs. 

```{r statistical test of normality}
# tests for normality: do these continuous data come from a normal (Gaussian) distribution?

#  the Shapiro-Wilk test is available in base r
shapiro.test(iris.sub$Petal.Length[iris.sub$Species == "virginica"])
shapiro.test(iris.sub$Petal.Length[iris.sub$Species == "versicolor"])
# the null hypothesis this is testing for is that there is no observable difference between the data and a normal distribution, so non-significant p-values indicate no evidence to reject null (in other words, data appear normally distributed)

# more tests for normality can be found in the "nortest" package: 'install.packages("nortest")'
install.packages("nortest")
library(nortest)
# anderson-darling test for normality
ad.test(iris.sub$Petal.Length[iris.sub$Species == "virginica"])
ad.test(iris.sub$Petal.Length[iris.sub$Species == "versicolor"])
```

## What statistical test should we choose to evaluate a difference between the 2 species?
The rest of the protocol is not applicable for a 2-sample comparison.
Now we take the information we have gleaned from exploration and decide what to do with it.  If data are normally distributed, we can run a t-test.  If not, alternative tests can be used

### for non-parametric data:
an independent 2-group Mann-Whitney U Test (also called Wilcoxon rank-sum test, or Wilcoxon-Mann-Whitney test) is a nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. It does not require that both pops be normally distributed, but do need to be applied to indep. samples and pops should have comparable types of distributions.  If the two distributions have a different shape, the Mann-Whitney U test is used to determine whether there are differences in the distributions of your two groups. However, if the two distributions are the same shape, the Mann-Whitney U test is used to determine whether there are differences in the medians of your two groups.

```{r statistical tests to compare populations}

# run a 2-tailed t.test
# follow the same model formula we have used in plotting one variable against another. here, y is numeric and A is a binary factor of the 2 populations you wish to compare
t.test(Petal.Length ~ Species, data=iris.sub)

# in R the default for this test is Welch's unequal var, so you have to specify if variances are equal (in this case minor differences in df and confidence intervals)
tt <- t.test(Petal.Length ~ Species, data=iris.sub, var.equal = TRUE)
tt
## if your hypothesis is that virginica is larger, for example, you can run a 1-tailed test.  In R the order is alphabetical unless you specify otherwise, so you are comparing relative to the first in an alphabetical list.
t.test(Petal.Length ~ Species, data=iris.sub, alternative = "less", var=TRUE)

# independent 2-group Mann-Whitney U Test (see caveats and assumptions above)
wilcox.test(Petal.Length ~ Species, data=iris.sub)
# where y is numeric and A is a binary factor

# similar to Kruskal Wallis Test One Way Anova by Ranks
kruskal.test(Petal.Length ~ Species, data=iris.sub)
```

# evaluate results:
These results make sense right?  All of our plots told us that the two species were considerably different.  Make sure your stats back up what you observe in the data, not the other way around!


# Exercise:
Run a similar analysis with either another variable from the iris or iris.sub data, or a dataset we worked with yesterday
Make sure to walk through the data exploration steps and then figure out what is the right test to use.


# Chi-squared test
if we have time and the interest, we can demostrate how to run a chi-squared test, otherwise I'll just leave this chunk of code in here for you all to play with in your free time.

```{r chi-squared test}

## A Chi-squared test is typically run on count data using a contingency table.  We will use a subset of the Flathead char data to build a contingency table (although the question is slightly contrived).

## Read in this flathead lake char data again
FLS <- read_csv("data/FlatheadLk_Salv.csv")
str(FLS)

# we are going to use a subset of these data to visualize better: 
# omit fall and just keep spring sampling; just use years after 2012
FLS2 <- FLS %>%   ## pipe data into filter
  filter(Section == "Spring", Survey_Year>2012)

unique(FLS2$Section) #check to make sure only data from spring sampling are included

# make a contingency table (a 2-way table) of year on species, with count (number of fish used to estimate the average) to evaluate whether year and species are independent of one another.  In other words, the alternative to the null would be that sample size was not independent of species and we might be suspicious of a sampling effect (e.g., higher effort in some years).  A contrived example to be sure.

# make a 2-way table of counts per year and species
Xcount <- xtabs(Count ~ Species + Survey_Year, 
                data = FLS2)
Xcount

# examine the data: what do you think the test will show?
barplot(Xcount,
  beside = TRUE,
  legend = TRUE,
  xlab = "Year",
  ylab = "Average Length",
  args.legend = list(x = 6, 
                     y = 80)
)

# Test the hypothesis Year is independent of Species at .05 significance level.
chisq.test(Xcount)

# the error message is a warning that because of the relatively small sample size, the Chi-squared approximation may be incorrect

# As the p-value 0.256 is greater than the .05 significance level,
# we do not reject the null hypothesis that species and year are independent
```


