## a little data management to make the intersection easier
row.names(counties) <- counties$COV_NAME
## intersect the geometries
intersect <- gIntersection(counties, p_grd, byid = T)
## plot the result, color to show that they are separate
plot(intersect, col = blues9)
## check the structure
str(intersect, max.level = 2)
# getting our data back from the intersection ----
## check the row.names of these polygons
row.names(intersect)
## these appear to be a concat of the first geometries row.names, and
## the second geometries row.names. We can work with that to get our data
## strsplit returns a list
tmp <- strsplit(row.names(intersect), split = ' ')
## iterate over the list to get either the 1st or 2nd element
county_name <- sapply(tmp, '[[', 1)
study_area <- sapply(tmp, '[[', 2)
## now we now which county and study area each polygon belongs to
## store this data in a data.frame
df_names <- data.frame(county_name = county_name, study_area = study_area, row.names = row.names(intersect))
## let's add the area of each polygon to this data.frame
## remember that the area for each polygon is stored
## with each Polygon object, and is in square meters
## below we will get the area and convert it to square kilometers
intersect@polygons[[1]]@area / 1e6
## lets iterate over the object to get this data
parea <- sapply(seq_along(intersect), function (i) intersect@polygons[[i]]@area / 1e6)
df_names$area <- parea
## finally, create a SpatialPolygonsDataFrame
new_polys <- SpatialPolygonsDataFrame(Sr = intersect, data = df_names)
## and just for completions sake... plot it
layout(matrix(1:3, nrow = 1, ncol = 3))
### plot colored by county
plot(new_polys, col = ggthemes::gdocs_pal()(17)[new_polys$county_name])
### plot colored by study area
plot(new_polys, col = ggthemes::gdocs_pal()(20)[new_polys$study_area])
### plot differentiating each polygon
plot(new_polys, col = blues9)
# Everything in R is a function call, almost ----
## are the following equal?
1 + 1 == `+`(1, 1)
## how about these?
county_name[[1]] == `[[`(county_name, 1)
# unioning polygons ----
## all of these function come from the rgeos package.
## select two counties to union
plot(counties[2:3, ])
## union them
nnv <- gUnion(counties[2, ], counties[3, ])
## plot the result
plot(nnv)
## inspect
str(nnv)
rm(nnv)
# union all interior polygons ----
## we ccan do the same thing to get a the border of NV
## use a different function, but same idea
nv <- gUnaryUnion(counties)
plot(nv)
# spTranform ----
## reproject
wgs_pts <- spTransform(spdf_points, CRS('+init=epsg:4326'))
## inspect coordinates
wgs_pts@coords[1:5, 1:2]
## we can do this to polygons too
wgs_counties <- spTransform(counties, CRS('+init=epsg:4326'))
## then we can plot the two counties projection side by side
layout(matrix(1:2, nrow=1, ncol=2))
plot(counties, main = 'UTM NAD83 zone 11')
plot(wgs_counties, main = 'WGS84')
## we can do this with other reprojections as well so you can really tell a difference
layout(matrix(1:8, nrow = 2, ncol = 4))
plot(spTransform(counties, CRS('+proj=aea')), main = 'Albers Equal Area', sub = 'USGS')
plot(spTransform(counties, CRS('+proj=sinu')), main = 'Van Der Grinten')
plot(spTransform(counties, CRS('+proj=robin')), main = 'Robinson')
plot(spTransform(counties, CRS('+proj=isea')), main = 'Icosahedral Snyder', sub = 'Dymaxion, Butterfly not open source')
plot(spTransform(counties, CRS('+proj=wintri')), main = 'Winkel-Tripel', sub = 'National Geographic')
plot(spTransform(counties, CRS('+proj=goode')), main = 'Goode Homolosine')
plot(spTransform(counties, CRS('+proj=eqc')), main = 'Plate Carree')
plot(spTransform(counties, CRS('+proj=gall')), main = 'Gall-Peters')
# working with raster data ----
## save some data for later
save(counties, spdf_points, wgs_pts, file = 'data/module2_6.RData')
## let's clean our workspace first
rm(bb, df_names, grd, intersect, new_polys, nnv, p_grd, rslt, tmp, wgs_counties, county_name, parea, study_area, counties, spdf_points, wgs_pts)
## load a raster
dem <- raster('data/nv_dem_coarse.grd')
## check dem structure
str(dem)
## what is this?
dem@data@inmemory
## plot raster
plot(dem)
## or
image(dem, asp = 1)
# load a second raster, distance to roads ----
road_rast <- raster('data/road_dist.grd')
## plot
plot(road_rast)
## use the raster::projection function
projection(road_rast)
projection(dem)
identicalCRS(road_rast, dem)
## compare to nv SpatialPolygonsDataFrame
identicalCRS(dem, nv)
projection(nv)
## proof these are the same crs
plot(dem)
plot(nv, lwd = 3, add = T)
## coerce projection
dem@crs <- nv@proj4string
road_rast@crs <- nv@proj4string
identicalCRS(dem, nv)
## check that we haven't screwed things up
plot(dem)
plot(nv, lwd = 3, add = T)
# load a second raster, distance to roads ----
road_rast <- raster('data/road_dist.grd')
## plot
plot(road_rast)
## mask raster to NV border. This will set all values outside NV to NA
nv_road_dist <- mask(road_dist, mask = nv, filename = 'output/nv_road_dist.grd', overwrite = T)
# create distance to roads ----
road_dist <- distance(road_rast, filename = "output/road_dist.grd", overwrite = T)
rmd2rscript("module2_1.Rmd")
rmd2rscript <- function(infile="module1_1.Rmd"){    # function for converting markdown to scripts
outfile1 <- gsub(".Rmd",".R",infile)
outfile2 <- gsub(".Rmd",".txt",infile)
close( file( outfile1, open="w" ) )   # clear output file
close( file( outfile2, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile1,"w")
con3 <- file(outfile2,"w")
stringToFind <- "```{r*"
isrblock <- FALSE
count=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
if(isrblock){
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if(count>1){
write(newline,file=con2,append=TRUE)
write(newline,file=con3,append=TRUE)
}
count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript2 <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("module2_1.Rmd")
rmd2rscript("module2_2.Rmd")
rmd2rscript("module2_3.Rmd")
rmd2rscript("module2_4.Rmd")
rmd2rscript2("module2_5.Rmd")
rmd2rscript2("module2_6.Rmd")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, message = FALSE)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, message = FALSE)
##################################################
####                                          ####
####  R Bootcamp #2, Module 3                 ####
####                                          ####
####   University of Nevada, Reno             ####
####                                          ####
##################################################
##################################################
####  Parallel processing in R                ####
####  Facilitator: Jonathan Greenberg         ####
####     jgreenberg@unr.edu                   ####
##################################################
data(geneData, package = "Biobase")   # load example data from Biobase package between all pairs of genes across all samples.
# This data represents 500 genes (organized by rows)
# with expression data (numerical).
# The goal is to calculate the correlation coefficient
# between all pairs of genes across all samples.  For example,
# to test gene 12 vs 13:
plot(geneData[12,],geneData[13,])    # plot the correlation between two genes
cor(geneData[12,],geneData[13,])
pair <- combn(1:nrow(geneData),2,simplify=F)   #leave this as a list, for now...
length(pair)
head(pair,n=3)     # note that the "head()" and "tail()" functions can be used on lists in addition to data frames...
tail(pair,n=3)
############
# New function: accepts a gene pair and the database as arguments and returns
# the correlation:
geneCor <- function(pair,gene=geneData){
cor(gene[pair[1],],gene[pair[2],])
}
# Test the function:
cor(geneData[12,],geneData[13,])
geneCor(pair=c(12,13),gene=geneData)    # should be the same result as the previous command...
########
# use "lapply" to run our function on the first three gene pairs
pair[1:3]
outcor <- lapply(pair[1:3],geneCor)
outcor
#################
# Examine processor use and speed
# First, open your task manager to view processor usage (see website for more details).
system.time(outcor <- lapply(pair,geneCor))
# Notice ONE CPU spiked.  Make note of how long it took to run.
fakeData <- cbind(geneData,geneData,geneData,geneData)    # make an even bigger dataset!
###########
# New, more complex function that generates bootstrap confidence intervals for correlation coefficients
library(boot)   # load the "boot" library for performing bootstrapping analysis
# 'x' represents vector with two elements, indicating the pair of genes to compare
# 'gene' represents a gene expression database
geneCor2 <- function(x, gene = fakeData){
mydata <- cbind(gene[x[1], ], gene[x[2], ])      # extract the rows (genes) to compare
mycor <- function(x, i) cor(x[i,1], x[i,2])     # function (correlation) to perform bootstrap analysis with
boot.out <- boot(mydata, mycor, 1000)           # perform bootstrap analysis (1000 iterations)
boot.ci(boot.out, type = "bca")$bca[4:5]         # extract and return the bootstrap confidence interval
}
# Test how long 10 pairs would take:
genCor2_system_time <- system.time(outcor <- lapply(pair[1:10],geneCor2))
genCor2_system_time["elapsed"]
length(pair)   # how many pairs were there again?
############
# estimate time to run 124,750 pairs
genCor2_system_time["elapsed"]      # time it took to run 10 pairs, in seconds
genCor2_system_time["elapsed"] *(124750/10)     # time it would take to run 124750 pairs, in seconds
genCor2_system_time["elapsed"] *(124750/10/60/60)    # in hours...
###########
# Explore parallel processing vs sequential processing
pair2 <- sample(pair,300)    # first extract a subsamble of all the pairs
# sequential mode:
registerDoSEQ() # Avoids warnings
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
load("data/module2_6.RData")
library(leaflet)
# interactive mapping ----
leaflet::leaflet(wgs_pts[1:100, ]) %>%
addTiles() %>%
addCircleMarkers(radius = 5)
?boot
tidyverse
?tidyverse
help(package="tidyverse")
biocLite("Biobase")
# First, load this script directly from the web (which also installs required packages for you!):
source("http://bioconductor.org/biocLite.R")
biocLite("Biobase")
knitr::opts_chunk$set(echo = TRUE)
rmd2rscript <- function(infile="module1_1.Rmd"){    # function for converting markdown to scripts
outfile1 <- gsub(".Rmd",".R",infile)
outfile2 <- gsub(".Rmd",".txt",infile)
close( file( outfile1, open="w" ) )   # clear output file
close( file( outfile2, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile1,"w")
con3 <- file(outfile2,"w")
stringToFind <- "```{r*"
isrblock <- FALSE
count=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
if(isrblock){
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if(count>1){
write(newline,file=con2,append=TRUE)
write(newline,file=con3,append=TRUE)
}
count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript2 <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript("module1_1.Rmd")
rmd2rscript("module1_2.Rmd")
rmd2rscript("module1_3.Rmd")
rmd2rscript("module2_1.Rmd")
rmd2rscript("module2_2.Rmd")
rmd2rscript("module2_3.Rmd")
rmd2rscript("module2_4.Rmd")
rmd2rscript2("module2_5.Rmd")
rmd2rscript2("module2_6.Rmd")
rmd2rscript("module2_3.Rmd")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
options(knitr.duplicate.label = 'allow')
##################################################
####                                          ####
####  R Bootcamp #2, Module 3                 ####
####                                          ####
####   University of Nevada, Reno             ####
####                                          ####
##################################################
##################################################
####  Parallel processing in R                ####
####  Facilitator: Jonathan Greenberg         ####
####     jgreenberg@unr.edu                   ####
##################################################
data(geneData, package = "Biobase")   # load example data from Biobase package between all pairs of genes across all samples.
# This data represents 500 genes (organized by rows)
# with expression data (numerical).
# The goal is to calculate the correlation coefficient
# between all pairs of genes across all samples.  For example,
# to test gene 12 vs 13:
plot(geneData[12,],geneData[13,])    # plot the correlation between two genes
cor(geneData[12,],geneData[13,])
pair <- combn(1:nrow(geneData),2,simplify=F)   #leave this as a list, for now...
length(pair)
head(pair,n=3)     # note that the "head()" and "tail()" functions can be used on lists in addition to data frames...
tail(pair,n=3)
############
# New function: accepts a gene pair and the database as arguments and returns
# the correlation:
geneCor <- function(pair,gene=geneData){
cor(gene[pair[1],],gene[pair[2],])
}
# Test the function:
cor(geneData[12,],geneData[13,])
geneCor(pair=c(12,13),gene=geneData)    # should be the same result as the previous command...
########
# use "lapply" to run our function on the first three gene pairs
pair[1:3]
outcor <- lapply(pair[1:3],geneCor)
outcor
#################
# Examine processor use and speed
# First, open your task manager to view processor usage (see website for more details).
system.time(outcor <- lapply(pair,geneCor))
# Notice ONE CPU spiked.  Make note of how long it took to run.
fakeData <- cbind(geneData,geneData,geneData,geneData)    # make an even bigger dataset!
###########
# New, more complex function that generates bootstrap confidence intervals for correlation coefficients
library(boot)   # load the "boot" library for performing bootstrapping analysis
# 'x' represents vector with two elements, indicating the pair of genes to compare
# 'gene' represents a gene expression database
geneCor2 <- function(x, gene = fakeData){
mydata <- cbind(gene[x[1], ], gene[x[2], ])      # extract the rows (genes) to compare
mycor <- function(x, i) cor(x[i,1], x[i,2])     # function (correlation) to perform bootstrap analysis with
boot.out <- boot(mydata, mycor, 1000)           # perform bootstrap analysis (1000 iterations)
boot.ci(boot.out, type = "bca")$bca[4:5]         # extract and return the bootstrap confidence interval
}
# Test how long 10 pairs would take:
genCor2_system_time <- system.time(outcor <- lapply(pair[1:10],geneCor2))
genCor2_system_time["elapsed"]
length(pair)   # how many pairs were there again?
############
# estimate time to run 124,750 pairs
genCor2_system_time["elapsed"]      # time it took to run 10 pairs, in seconds
genCor2_system_time["elapsed"] *(124750/10)     # time it would take to run 124750 pairs, in seconds
genCor2_system_time["elapsed"] *(124750/10/60/60)    # in hours...
###########
# Explore parallel processing vs sequential processing
pair2 <- sample(pair,300)    # first extract a subsamble of all the pairs
# Let's test a sequential version of this:
system.time(outcor <- lapply(pair2,geneCor2))
###########
# Run this operation in parallel!!
### parallel: built-in parallel computation package.
library("parallel")       # load the package (comes with basic R installation)
install.packages("future")    # install "future" package, which we will use later
library("future")
########
# Make a cluster
myCluster <- parallel::makeCluster(spec=4,type="PSOCK")    # make cluster with 4 cpus of type "PSOCK"
myCluster
length(myCluster) # One entry per "worker".
myCluster[[1]]    # more info about this "worker"
date()    # run the "date()" function
workerDates <- parallel::clusterCall(cl=myCluster,fun=date)    # now try running the "date()" function on all clusters
class(workerDates)
length(workerDates) # One list element per worker.
####
# explore packages loaded in our worker environments
search()
workerPackages <- parallel::clusterCall(cl=myCluster,fun=search)
# workerPackages
####
# explore packages loaded in our worker environments
search()      # packages loaded in global environment
workerPackages <- parallel::clusterCall(cl=myCluster,fun=search)     # .. and worker environments
# workerPackages
loadOnCls <- parallel::clusterEvalQ(cl=myCluster,library("boot"))
loadData <- parallel::clusterExport(cl=myCluster,"fakeData")
#######
# Call the "geneCor2()" function for each gene pair, using parallel processing
system.time(outcor2 <- parallel::clusterApplyLB(cl=myCluster,pair2,geneCor2))
# vs the non-clustered version:
system.time(outcor <- lapply(pair2,geneCor2))   # takes much longer!
library("foreach")
library("doParallel")
# sequential mode:
registerDoSEQ() # Avoids warnings
system.time(
outcor <- foreach(
p = pair2,
.packages="boot",
.combine="rbind") %dopar% {
return(geneCor2(p))
}
)
myCluster
# Register the backend with foreach (doParallel):
registerDoParallel(myCluster)
# Run our code! Notice I didn't change the foreach call at all:
system.time(
outcor <- foreach(
p = pair2,
.packages="boot",
.combine="rbind") %dopar% {
return(geneCor2(p))
}
)
geneCor2
?foreach
# Register the backend with foreach (doParallel):
registerDoParallel(myCluster)
# Run our code! Notice I didn't change the foreach call at all:
system.time(
outcor <- foreach(
p = pair2,
.packages="boot",
.export="geneCor2",
.combine="rbind") %dopar% {
return(geneCor2(p))
}
)
# Register the backend with foreach (doParallel):
registerDoParallel(myCluster)
# Run our code! Notice I didn't change the foreach call at all:
system.time(
outcor <- foreach(
p = pair2,
.packages="boot",
.export=c("geneCor2"),
.combine="rbind") %dopar% {
return(geneCor2(p))
}
)
parallel::clusterEvalQ(cl=myCluster,ls())
parallel::clusterCall(cl=myCluster,fun=search)
loadData <- parallel::clusterExport(cl=myCluster,"geneCor2")
parallel::clusterEvalQ(cl=myCluster,ls())
# Register the backend with foreach (doParallel):
registerDoParallel(myCluster)
# Run our code! Notice I didn't change the foreach call at all:
system.time(
outcor <- foreach(
p = pair2,
.packages="boot",
.export=c("geneCor2"),
.combine="rbind") %dopar% {
return(geneCor2(p))
}
)
rmd2rscript("module2_3.Rmd")
tribble
tibble
library(tidyverse)
library(tidyverse)
tibble
tribble
?tribble
rmd2rscript2("module2_6.Rmd")
search()
rmd2rscript("module2_4.Rmd")
rmd2rscript2("module2_4.Rmd")
rmd2rscript2("module2_4.Rmd")
